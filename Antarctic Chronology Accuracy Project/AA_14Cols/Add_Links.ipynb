{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os\n",
    "import yaml\n",
    "import itertools\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WDC</th>\n",
       "      <th>EDC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.480791</td>\n",
       "      <td>21.101114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.272790</td>\n",
       "      <td>22.037936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110.263453</td>\n",
       "      <td>23.103062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>142.970815</td>\n",
       "      <td>29.642998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144.181778</td>\n",
       "      <td>29.860624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>3320.220000</td>\n",
       "      <td>893.606700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>3320.900000</td>\n",
       "      <td>894.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>3326.845900</td>\n",
       "      <td>900.908280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>3337.889600</td>\n",
       "      <td>913.245500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>3338.893500</td>\n",
       "      <td>914.426050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>566 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             WDC         EDC\n",
       "0     100.480791   21.101114\n",
       "1     105.272790   22.037936\n",
       "2     110.263453   23.103062\n",
       "3     142.970815   29.642998\n",
       "4     144.181778   29.860624\n",
       "..           ...         ...\n",
       "561  3320.220000  893.606700\n",
       "562  3320.900000  894.329100\n",
       "563  3326.845900  900.908280\n",
       "564  3337.889600  913.245500\n",
       "565  3338.893500  914.426050\n",
       "\n",
       "[566 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_links = pd.read_excel('/Users/quinnmackay/Documents/GitHub/BICC/Data Storage/Tiepoints/WDC-EDML_WDC-EDC_WDC-TALDICE.xlsx', sheet_name=2, skiprows=44, usecols=[0,1], names=['WDC', 'EDC']) \n",
    "\n",
    "comment_add = ''\n",
    "sv_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup completed: /Users/quinnmackay/Documents/GitHub/BICC/Paleochrono BICC Work/Paleochrono BICC Experiment/Backups/BICC_Backup_20251111_133858\n"
     ]
    }
   ],
   "source": [
    "backups=False\n",
    "folder='AA_14Cols'\n",
    "error=10\n",
    "\n",
    "if backups == True:\n",
    "    # add backup of BICC\n",
    "\n",
    "    source_folder = f'/Users/quinnmackay/Documents/GitHub/BICC/Antarctic Chronology Accuracy Project/{folder}'\n",
    "    backup_root = f'/Users/quinnmackay/Documents/GitHub/BICC/Antarctic Chronology Accuracy Project/{folder}/Backups'\n",
    "\n",
    "    # Create timestamp\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    backup_folder = os.path.join(backup_root, f'BICC_Backup_{timestamp}')\n",
    "\n",
    "    # Make sure the backup root exists\n",
    "    os.makedirs(backup_root, exist_ok=True)\n",
    "\n",
    "    # Copy the folder\n",
    "    shutil.copytree(source_folder, backup_folder)\n",
    "\n",
    "    print(f\"Backup completed: {backup_folder}\")\n",
    "else:\n",
    "    print(\"Backups not enabled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cores list from params\n",
    "params = f'/Users/quinnmackay/Documents/GitHub/BICC/Antarctic Chronology Accuracy Project/{folder}/parameters.yml'\n",
    "with open(params, 'r') as f:\n",
    "    first_line = f.readline()\n",
    "params_load = yaml.safe_load(first_line)\n",
    "list_sites = params_load['list_sites']\n",
    "\n",
    "# get all link combos\n",
    "pairs = [f\"{a}-{b}\" for a, b in itertools.combinations(list_sites, 2)]\n",
    "\n",
    "#get all combos possible from the svensson links\n",
    "subset = list(sv_links.columns)\n",
    "valid_pairs = [p for p in pairs if all(site in subset for site in p.split('-'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DF-WDC: 533 rows\n"
     ]
    }
   ],
   "source": [
    "#now, create all the link files\n",
    "sv_synchros = {}\n",
    "sv_comments = {}\n",
    "for pair in valid_pairs:\n",
    "    site_a, site_b = pair.split('-')\n",
    "\n",
    "    # Drop NaN rows to get only valid shared tiepoints\n",
    "    sv_synchros[pair] = sv_links[[site_a, site_b]].dropna()\n",
    "    sv_synchros[pair].columns = ['depth1', 'depth2']\n",
    "    sv_synchros[pair]['age_unc'] = error\n",
    "    sv_synchros[pair]['comment'] = np.nan  # Initialize age column with NaN\n",
    "\n",
    "    sv_comments[pair] = [comment_add]\n",
    "\n",
    "#now load existing synchros\n",
    "os.chdir(f'/Users/quinnmackay/Documents/GitHub/BICC/Antarctic Chronology Accuracy Project/{folder}')\n",
    "existing_synchros = {}\n",
    "existing_comments = {}\n",
    "\n",
    "for pair in valid_pairs:\n",
    "    folder_path = pair\n",
    "    file_path = os.path.join(folder_path, \"iceice_synchro_horizons.txt\")\n",
    "\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "\n",
    "        comments = []\n",
    "        with open(file_path, 'r') as f: # store existing comments to be re-added\n",
    "            for line in f:\n",
    "                if line.startswith('#'):\n",
    "                    comments.append(line.rstrip('\\n'))  # keeps tabs intact  # store comment lines without newline\n",
    "        existing_comments[pair] = comments\n",
    "\n",
    "        try:\n",
    "            synchros = pd.read_csv(file_path, sep='\\t', comment='#')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {pair}: {e}\")\n",
    "            print(f'File Path: {file_path}')\n",
    "            sys.exit()\n",
    "\n",
    "        existing_synchros[pair] = synchros\n",
    "        print(f\"Loaded {pair}: {len(synchros)} rows\")\n",
    "    else:\n",
    "        print(f\"Skipped {pair} — file not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 404.37562839 2155.595        20.                   nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 452.51299174 2345.11         20.                   nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 472.58308679 2405.475        20.                   nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 484.3295617 2433.985       20.                 nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 484.98310248 2435.595        20.                   nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 539.57022628 2561.645        20.                   nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 542.11337301 2567.235        20.                   nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 544.20318908 2572.045        20.                   nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 550.94328015 2586.485        20.                   nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 579.52484573 2653.049408     20.                   nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 599.71638884 2707.851555     20.                   nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 611.34494837 2742.855        20.                   nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Warning: Partial overlap detected for pair DF-WDC at new tiepoint [ 618.0854183 2762.795       20.                 nan]. One column is within 0.1 of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\n",
      "Saved merged synchro for DF-WDC with rows to DF-WDC/iceice_synchro_horizons.txt\n",
      "There were 533 existing rows, 121 overlaps (13 error overlaps), and 0 new ties.\n"
     ]
    }
   ],
   "source": [
    "tolerance = 0.10  # meters\n",
    "\n",
    "for pair in valid_pairs:\n",
    "\n",
    "    if pair in existing_synchros:\n",
    "        \n",
    "        overlaps = 0\n",
    "        new_ties = 0\n",
    "        error_overlaps = 0\n",
    "\n",
    "        existing = existing_synchros[pair].copy(deep=True)\n",
    "        new = sv_synchros[pair].copy(deep=True)\n",
    "\n",
    "        total_existing = len(existing)\n",
    "\n",
    "        # Start with originals (priority)\n",
    "        combined = existing.copy(deep=True)\n",
    "\n",
    "        # Append only existing tiepoints that are NOT close to any new tiepoint\n",
    "        for idx, row in new.iterrows():\n",
    "\n",
    "            mask_either = ( #check for either column within tolerance. Does NOT append if either is close.\n",
    "                (abs(existing.iloc[:, 0] - row.iloc[0]) <= tolerance) |\n",
    "                (abs(existing.iloc[:, 1] - row.iloc[1]) <= tolerance)\n",
    "            )\n",
    "            mask_both = ( #check for both columns to spit out error if needed\n",
    "                (abs(existing.iloc[:, 0] - row.iloc[0]) <= tolerance) &\n",
    "                (abs(existing.iloc[:, 1] - row.iloc[1]) <= tolerance)\n",
    "            )\n",
    "\n",
    "            if not mask_either.any():\n",
    "                combined = pd.concat([combined, row.to_frame().T], ignore_index=True)\n",
    "                new_ties+=1\n",
    "            else:\n",
    "                overlaps += 1\n",
    "\n",
    "            if mask_either.any() and not mask_both.any():\n",
    "                print(f\"Warning: Partial overlap detected for pair {pair} at new tiepoint {row.values}. One column is within {tolerance} of an existing tiepoint, while other is not. The tiepoint was not added to avoid conflicts.\")\n",
    "                error_overlaps += 1\n",
    "\n",
    "        #duplicate check\n",
    "        before = len(combined)\n",
    "        combined = combined.drop_duplicates(ignore_index=True)\n",
    "        after = len(combined)\n",
    "\n",
    "        if after < before:\n",
    "            print(f\"Warning: {before - after} duplicate tiepoint(s) found and removed in pair {pair}.\")\n",
    "\n",
    "        folder_path = pair\n",
    "        file_path = os.path.join(folder_path, \"iceice_synchro_horizons.txt\")\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        # --- Gather comments ---\n",
    "        new_comments = sv_comments.get(pair, [])\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            # Write new comments first\n",
    "            if new_ties > 0:\n",
    "                for line in new_comments:\n",
    "                    f.write(f\"{line}\\n\")\n",
    "            # Add original comments\n",
    "            for line in existing_comments.get(pair, []):\n",
    "                f.write(f\"{line}\\n\")\n",
    "            # Write merged DataFrame below\n",
    "            combined.to_csv(f, sep='\\t', index=False)\n",
    "        print(f\"Saved merged synchro for {pair} with rows to {file_path}\\nThere were {total_existing} existing rows, {overlaps} overlaps ({error_overlaps} error overlaps), and {new_ties} new ties.\")\n",
    "\n",
    "    else:\n",
    "        folder_path = pair\n",
    "        file_path = os.path.join(folder_path, \"iceice_synchro_horizons.txt\")\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        combined = sv_synchros[pair].copy(deep=True) # svensson links load\n",
    "        new_comments = sv_comments.get(pair, [])\n",
    "\n",
    "        with open(file_path, 'w') as f:\n",
    "            # Write new comments first\n",
    "            for line in new_comments:\n",
    "                f.write(f\"#{line}\\n\")\n",
    "            # Write merged DataFrame below\n",
    "            combined.to_csv(f, sep='\\t', index=False)\n",
    "\n",
    "        print(f\"No existing synchros for {pair}, saving new synchro to {file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bicc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
